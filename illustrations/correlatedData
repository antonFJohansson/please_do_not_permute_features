

from scipy.stats import multivariate_normal
import numpy as np
import matplotlib.pyplot as plt
import random

num_data_pt = 100
mu = np.array([0,0.])
sig = np.array([[1, 0.97], [0.97, 1]])
data_corr = multivariate_normal.rvs(mu, sig, num_data_pt)
y_corr = 2*data_corr[:,0]**2 + 0.001*data_corr[:,1]**2 + np.random.normal(0,0.1, num_data_pt)**2 + 1

figure, ax = plt.subplots(1,2, figsize = (12, 6))
ax[0].plot(data_corr[:,0], data_corr[:,1], 'bo',alpha = 0.6)
ax[0].set_xlim(-3,3)
ax[0].set_ylim(-3,3)
ax[0].grid()

random_ind = [ttt for ttt in range(num_data_pt)]
random.shuffle(random_ind)

ax[1].plot(data_corr[:,0], data_corr[:,1], 'bo',alpha = 0.6, label="Original data")
ax[1].plot(data_corr[:,0], data_corr[random_ind,1], 'ro', alpha = 0.6, label="Permuted data")
ax[1].set_xlim(-3,3)
ax[1].set_ylim(-3,3)
ax[1].grid()
ax[1].legend()

ax[0].set_xlabel('x')
ax[0].set_ylabel('y')

ax[1].set_xlabel('x')
ax[1].set_ylabel('y')

ax[0].set_title('Original data')
ax[1].set_title('Permuted data superimposed on original data')


## Below here we showcase the neural network fitting


## We need to convert it to training data here for the network
import torch
import torch.nn as nn 
import torch.nn.functional as F

list_train_corr = [(torch.from_numpy(data_corr[i,:]).float(), torch.tensor([y_corr[i]]).float()) for i in range(num_data_pt)] 
class Network(nn.Module):

  def __init__(self, init_dim, out_dim):
    super().__init__()
    self.fc1 = nn.Linear(init_dim, 5)
    self.fc2 = nn.Linear(5, out_dim)
  
  def forward(self, x):
    x = F.relu(self.fc1(x))
    x = self.fc2(x)
    return x


import random

net_stores = []
num_des_nets = 5

for ooo in range(num_des_nets):
  new_net = Network(2,1)
  opt = torch.optim.SGD(new_net.parameters(), lr=1e-3, momentum=0.9)
  loss_fn = nn.MSELoss()

  num_epochs = 10
  for epoch in range(num_epochs):

    random.shuffle(list_train_corr)
    tot_loss = 0.
    for x,y in list_train_corr:
      new_net.zero_grad()
      x = torch.unsqueeze(x, dim=0)
      y = torch.unsqueeze(y, dim=0)
      out = new_net(x)
      #print(x,y)
      loss = loss_fn(out,y)
      tot_loss = tot_loss + loss.item()
      loss.backward()
      opt.step()
  ## train it a little bit better maybe?
  net_stores.append(new_net)
  
  
## So now we just want to plot our nn function

X = np.arange(-3, 3, 0.025)
Y = np.arange(-3, 3, 0.025)
X, Y = np.meshgrid(X, Y)
Z_store = []

for net in net_stores:
  Z = np.zeros((X.shape[0], Y.shape[0]))
  for iii in range(X.shape[0]):
    for jjj in range(Y.shape[0]):

      data_pt = torch.tensor([[X[iii,jjj], Y[iii,jjj]]]).float()
      out = net(data_pt)
      Z[iii, jjj] = out.item()
  Z_store.append(Z)
  #  X_t = X[]



#R = np.sqrt(X**2 + Y**2)
#Z = np.sin(R)


from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import

import matplotlib.pyplot as plt
from matplotlib import cm
from matplotlib.ticker import LinearLocator, FormatStrFormatter
import numpy as np


fig = plt.figure(figsize=(15,15))
ax = fig.gca(projection='3d')

# Make data.
# X = np.arange(-5, 5, 0.025)
# Y = np.arange(-5, 5, 0.025)
# X, Y = np.meshgrid(X, Y)
# R = np.sqrt(X**2 + Y**2)
# Z = np.sin(R)

# Plot the surface.

cm_maps = [cm.coolwarm, cm.Spectral, cm.winter, cm.viridis, cm.afmhot]
#cm_maps = 5*[cm.coolwarm]
for idx,Z in enumerate(Z_store):
  surf = ax.plot_surface(X, Y, Z, cmap=cm_maps[idx],#cm.Spectral,
                        linewidth=0, antialiased=True)
#ax.scatter(data_corr[:,0], data_corr[:,1],data_corr.shape[0]*[0], marker = 'o')

ax.plot(data_corr[:,0], data_corr[:,1], 'bo',alpha = 0.6, label="Original data", zs=[0])
ax.plot(data_corr[:,0], data_corr[random_ind,1], 'ro', alpha = 0.6, label="Permuted data", zs=[0])
# Customize the z axis.
#ax.set_zlim(-1.01, 1.01)
ax.zaxis.set_major_locator(LinearLocator(10))
#ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))
ax.set_xlabel('x')
ax.set_ylabel('y')
ax.view_init(25, 45)
ax.set_zticks([kkk for kkk in range(0,20,2)])
ax.set_zlim(0, 18)
# Add a color bar which maps values to colors.
#fig.colorbar(surf, shrink=0.5, aspect=10)
ax.set_zlabel('z')
ax.set_title('5 different neural network functions')

#plt.show()



